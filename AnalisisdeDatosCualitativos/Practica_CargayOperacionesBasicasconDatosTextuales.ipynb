{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python379jvsc74a57bd0fcc1d2c210046f8d6f0962280d91bf96fd89619bab60881df3e6b70c67140f94",
   "display_name": "Python 3.7.9 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Ejercicio 1: Análisis preliminar de entrevistas\n",
    "\n",
    "Eres parte de un grupo de investigación enfocado en la toma de decisiones vocacionales. El grupo acaba de recibir una transcripción de entrevistas para analizar. Antes de seguir la ruta tradicional de análisis cualitativo, te han solicitado que puedas explorar la información textual presente en las entrevistas. \n",
    "\n",
    "Primero, corresponde cargar la transcripción de entrevistas, provista en formato PDF. A continuación se presenta el funcionamiento básico de la librería PyPDF2:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting PyPDF2\n  Downloading PyPDF2-1.26.0.tar.gz (77 kB)\nBuilding wheels for collected packages: PyPDF2\n  Building wheel for PyPDF2 (setup.py): started\n  Building wheel for PyPDF2 (setup.py): finished with status 'done'\n  Created wheel for PyPDF2: filename=PyPDF2-1.26.0-py3-none-any.whl size=61085 sha256=d88b60b590bd0254be4e8c2251fe7bb5d868f156f28b3340b7a34e6a1b3345a2\n  Stored in directory: c:\\users\\renat\\appdata\\local\\pip\\cache\\wheels\\80\\1a\\24\\648467ade3a77ed20f35cfd2badd32134e96dd25ca811e64b3\nSuccessfully built PyPDF2\nInstalling collected packages: PyPDF2\nSuccessfully installed PyPDF2-1.26.0\n"
     ]
    }
   ],
   "source": [
    "# Instalar el paquete PyPDF2\n",
    "!pip install PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "92\n1\n \n \n1.\n \nEntrevista 1\n \n \nEstudiante 1 de género masculino, universidad pública, \npsicología\n, que proviene de \nliceo\n \ncientífico \n\n \nhumanista A (entrevistado el 6 de enero de 2014).\n \n \n \nIniciando mi nombre es \nentrevistado uno\n, tengo 20 años, estudio \npsicología\n \nen la \nuniversidad pública\n, estoy, pasé a tercer año de la carrera y egresé, la enseñanza media la \ncursé en el liceo\n \ncientífico \n\n \nhumanista A \nde la comuna de P. A.\n \n \nEl Liceo, ¿es municipal?\n \n \nEs municipal, si, uno de los otrora emblemáticos de \ncomuna de P. A. \nque ahora está de mal \nen peor, con mucho estudiante en riesgo social, muy vulnerable, con matrícula reducida \npara\n \nlo que es su infraestructura. No, es como quizás da cuenta la situación de la educación \nmunicipal y de la educación pública a nivel medio en Chile, que están siendo vejados en \nfunción de lo privado, eso.\n \n \nHa venido como disminuyéndose. Mira, la pregunta q\nue guía la siguiente entrevista es \nmás menos ¿cómo fue tu proceso de decisión vocacional tanto en tu etapa escolar, \nconsiderando elementos de tu historia de vida hasta más menos como has llegado \nahora, cómo llegaste en el fondo a tomar esta decisión en el \ncontexto de oportunidades \nque se te dio?\n \n \n\nahí. Bueno, cuando yo era chico, tenía alrededor de diez años pertenecí a una congregación \nreligiosa que entre otras cosas ins\ntaba a los jóvenes a hacer una especie de misión que se \nllama, en la cual tu cumples diecinueve años y tienes que servir por dos años a tu religión \nhaciendo proselitismo religioso en otro país por lo general. Entonces mis padres siempre \nme inculcaron que y\no tenía que hacer eso y posterior a ello yo podía estudiar no sé, algún \nbachillerato, algo así que ellos me iban a poder financiar la carrera. Bueno, después con los \nvaivenes de la vida yo salí afortunadamente de esa congregación religiosa, puedo decir que\n \nvi la luz al salir.\n \n \n¿Qué edad tenías ahí más menos?\n \n \nDiecisiete años cuando sucedió eso pero antes de eso igual mucho, muchas situaciones, \ncambios de empleo de mi viejo que le bajaron el sueldo, que a mi vieja le subieron el \nsueldo, muchas situaciones ca\nmbiaron, entonces ahí tu por medio de tus viejos, no tanto \nmis viejos quizás, sino que más que nada sentía la presión de que tenía que hacerlo porque \n\n \nque \n\n\nporque sino ingresas a la universidad, pucha, vas a ser un pollo, \ncachai\n.\n \n \n¿Qué significa ser un pollo?\n \n \n\n"
     ]
    }
   ],
   "source": [
    "# Importar paquetes a ser utilizados\n",
    "import matplotlib.pyplot as plt\n",
    "import PyPDF2\n",
    "import nltk\n",
    "\n",
    "# crea un objeto de archivo pdf\n",
    "pdfFileObj = open('Anexo_Entrevistas.pdf', 'rb')\n",
    " \n",
    "# crea un objeto de lectura de pdf\n",
    "pdfReader = PyPDF2.PdfFileReader(pdfFileObj)\n",
    " \n",
    "# muestra el número de páginas en un archivo pdf\n",
    "print(pdfReader.numPages)\n",
    " \n",
    "# crea un objeto de página\n",
    "pageObj = pdfReader.getPage(2)\n",
    " \n",
    "# extrae text de una página\n",
    "print(pageObj.extractText())"
   ]
  },
  {
   "source": [
    "1. Extrae los `tokens` presentes en las entrevistas y genera un objeto `Text` usando la librería NLTK (Recuerda seleccionar solo aquellas páginas del documento en las que estén los datos de la entrevista). "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escribe tu respuesta aquí"
   ]
  },
  {
   "source": [
    "2. Calcula la cantidad de palabras distintas presentes en la entrevista, así como su diversidad léxica. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escribe tu respuesta aquí"
   ]
  },
  {
   "source": [
    "3. Genera una visualización de la distribución de frecuencia de las 100 palabras más usadas durante las entrevistas \n",
    "(Sugerencia: utiliza el método `plot` disponible en el objeto Text creado previamente)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escribe tu respuesta aquí"
   ]
  },
  {
   "source": [
    "4. Crea un **Lexical Dispersion Plot** con las palabras `universidad`, `gusta`, `plata`, `viejos`, `colegio`, `amigos`, `carrera`.\n",
    "(Sugerencia: utiliza el método `dispersion_plot` disponible en el objeto Text creado previamente)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escribe tu respuesta aquí"
   ]
  },
  {
   "source": [
    "5. Crea un texto generado aleatoriamente a partir de un modelo de lenguaje con el método `generate` disponible en el objeto Text creado previamente. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escribe tu respuesta aquí"
   ]
  },
  {
   "source": [
    "6. Ahora, realiza realiza estos mismos pasos (cálculo de diversidad léxica, plot, dispersion_plot y generate) con el entrevistado 2 y el entrevistado 5 por separado. ¿Encuentras alguna diferencia?"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Ejercicio 2: Análisis preliminar de hasthags en Twitter\n",
    "\n",
    "Eres parte de una empresa consultora de Community Management. Parte de tu labor es reportar el \"pulso\" de la sociedad peruana (que habita Twitter) a partir del análisis de tweets.\n",
    "\n",
    "Dada la coyuntura, se te pide que analices dos hasthags: `#CambioViciadoPorElLapiz` y `#CambioViciadoPorKeiko`\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importa las librerías a utilizar\n",
    "import tweepy\n",
    "import re\n",
    "from unicodedata import normalize\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from wordcloud import WordCloud\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download(\"stopwords\")\n",
    "\n",
    "# Variables con las credenciales de acceso al API de Twitter\n",
    "consumerKey = \"TYPE HERE\"\n",
    "consumerSecret = \"TYPE HERE\"\n",
    "accessToken = \"TYPE HERE\"\n",
    "accessTokenSecret = \"TYPE HERE\"\n",
    "\n",
    "# Acceso al API de Twitter\n",
    "auth = tweepy.OAuthHandler(consumerKey, consumerSecret)\n",
    "auth.set_access_token(accessToken, accessTokenSecret)\n",
    "api = tweepy.API(auth)"
   ]
  },
  {
   "source": [
    "1. Extrae 2500 tweets que utilicen los hashtags mencionados y colócalos en dos listas separadas. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escribe tu respuesta aquí"
   ]
  },
  {
   "source": [
    "2. Crea dos Series de Pandas a partir de estas listas. Retira los duplicados y quita los caracteres indeseados. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Puedes usar estas funciones para remover los caracteres indeseados.\n",
    "remove_rt = lambda x: re.sub('RT @\\w+: ',\" \",x)\n",
    "remove_tilde = lambda x: re.sub(\n",
    "    \tr\"([^n\\u0300-\\u036f]|n(?!\\u0303(?![\\u0300-\\u036f])))[\\u0300-\\u036f]+\", r\"\\1\", \n",
    "    \tnormalize( \"NFD\", x), 0, re.I)\n",
    "rt = lambda x:  re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\",\" \",x)\n",
    "\n",
    "# Escribe tu respuesta aquí"
   ]
  },
  {
   "source": [
    "3. Crea dos nubes de palabras con los tweets de cada hashtag. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Puedes usar esta función para crear las nubes de palabras\n",
    "def create_wordcloud(text):\n",
    "    mask = np.array(Image.open(\"cloud.png\"))\n",
    "    mystopwords = set(stopwords.words('spanish', 'english'))\n",
    "    mystopwords.update([\"cambioviciadoporkeiko\",\"cambioviciadoporellapiz\"]) \n",
    "    wc = WordCloud(background_color=\"white\",\n",
    "                  mask = mask,\n",
    "                  max_words=3000,\n",
    "                  stopwords=mystopwords,\n",
    "                  collocations=False)\n",
    "    wc.generate(str(text))\n",
    "    plt.figure(figsize=(40, 20))\n",
    "    plt.imshow(wc)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escribe tu respuesta aquí"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escribe tu respuesta aquí"
   ]
  },
  {
   "source": [
    "4. Crea un textos generados aleatoriamente a partir de un modelo de lenguaje de cada uno de los hashtags."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escribe tu respuesta aquí"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escribe tu respuesta aquí"
   ]
  }
 ]
}